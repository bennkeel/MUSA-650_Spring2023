{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1 - Basics of ML\n",
    "Include your code in the relevant cells below.\n",
    "Subparts labeled as questions (Q1.1, Q1.2, etc.) should have their answers filled in or plots placed prominently, as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important notes: \n",
    "\n",
    "1. On this and future homeworks, depending on the data size and your hardware configuration, experiments may take too long if you use the complete dataset. This may be challenging, as you may need to run multiple experiments. So, if an experiment takes too much time, start first with a smaller sample that will allow you to run your code within a reasonable time. Once you complete all tasks, before the final submission, you can allow longer run times and run your code with the complete set. However, if this is still taking too much time or causing your computer to freeze, it will be OK to submit experiments using a sample size that is feasible for your setting (indicate it clearly in your submission). Grading of the homework will not be affected from this type of variations in the design of your experiments.\n",
    "\n",
    "\n",
    "2. You can switch between 2D image data and 1D vector data using the numpy functions flatten() and resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1: Understanding the data\n",
    "- Load MNIST dataset (hint it's available as part of https://keras.io/api/datasets)\n",
    "\n",
    "\n",
    "Q1.1: What is the number of features in the training dataset:   784\n",
    "\n",
    "Q1.2: What is the number of samples in the training dataset:  60,000\n",
    "\n",
    "Q1.1: What is the number of features in the testing dataset:   784\n",
    "\n",
    "Q1.4: What is the number of samples in the testing dataset:   10,000\n",
    "\n",
    "Q1.3: What is the dimensionality of each data sample: 2-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2: Viewing the data\n",
    "- Select one random example from each category from the training set. Display the 2D image with the name of the category\n",
    "\n",
    "Q2.1: Visualize the example image:   ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(330 + 1 + 1)\n",
    "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3: Sub-sampling the data\n",
    "- Reduce training and testing sample sizes by **randomly selecting** %10 of the initial samples\n",
    "\n",
    "Q3.1: What is the distribution of each label in the initial train data (i.e. percentage of each label):   ___\n",
    "\n",
    "Q3.2: What is the distribution of each label in the reduced train data:   ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S4: Sub-sampling the data (again)\n",
    "- Reduce training and testing sample sizes by selecting **the first** %10 of the initial samples\n",
    "\n",
    "Q4.1: What is the distribution of each label in the initial train data (i.e. percentage of each label):   ___\n",
    "\n",
    "Q4.2: What is the distribution of each label in the reduced train data:   ___\n",
    "\n",
    "Q4.3: What are your comments/interpretation on comparison of the results for S3 and S4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! For the rest of the HW, please discard sub-sampled data from S3 and use subsampled data from S4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S5: Exploring the dataset\n",
    "- Select all **train** images in category \"3\". Create and display a single pixel-wise \"average image\" for this category.\n",
    "- Create and display a single pixel-wise \"standard deviation image\" for this category?\n",
    "- Repeat the items above for category \"3\" images in the **test** set. Compare the average and standard deviation images.\n",
    "- Repeat the items above for a different category you select.\n",
    "\n",
    "Q5.1: Plot the 2D mean and std images for category 3 in training and testing sets:   ___\n",
    "\n",
    "Q5.2: Plot the 2D mean and std images for the category you selected in training and testing sets:   ___\n",
    "\n",
    "Q5.3: Comment on differences between the mean and std images from training and testing datasets? ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S6: Image distances\n",
    "- In the training set, find the image in category 3 that is most dissimilar to the mean image of category 3. Show it as a 2D image\n",
    "- In the training set, find the image in category 3 that is most similar to mean image of category 3. Show it as a 2D image\n",
    "- In the training set, find the image in category 9 that is most similar to mean image of category 3. Show it as a 2D image\n",
    "\n",
    "**Hint:** You can use the \"euclidean distance\" as your similarity metric. Given that an image i is represented with a flattened feature vector v_i , and the second image j with v_m, the distance between these two images can be calculated using the vector norm of their differences ( | v_i - v_j | ) \n",
    "\n",
    "Q6.1: What is the index of most dissimilar image in category 3:   ___\n",
    "\n",
    "Q6.2: Plot the most dissimilar category 3 image in 2D:   ___\n",
    "\n",
    "Q6.3: Plot the most similar category 3 image in 2D:   ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7: Image distances, part 2\n",
    "- Repeat questions S3 and S4 after binarizing the images first\n",
    "\n",
    "Q7.1: What is the index of most dis-similar category 3 image:   ___\n",
    "\n",
    "Q7.2: What is the index of most similar category 3 image:   ___\n",
    "\n",
    "Q7.3: Did the answer change after binarization? How do you interprete this finding?:   ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S8: Binary classification between category 3 and 9  (split train data)\n",
    "- Select images from these two categories in the training dataset\n",
    "- Split them into two sets (Set1, Set2) with a %60 and %40 random split\n",
    "- Replace category labels as 0 (for 3) and 1 (for 9)\n",
    "- Use Set1 to train a linear SVM classifier with default parameters and predict the class labels for Set2 \n",
    "- Use Set2 to train a linear SVM classifier with default parameters and predict the class labels for Set1 \n",
    "\n",
    "Q8.1: What is the prediction accuracy using the model trained on Set1:   ___\n",
    "\n",
    "Q8.2: What is the prediction accuracy using the model trained on Set2:   ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S9: Binary classification between category 3 and 9 (train + test sets)\n",
    "- Select images from these two categories in the training and testing datasets\n",
    "- Replace category labels as 0 (for 3) and 1 (for 9)\n",
    "- Use training set to train a linear SVM classifier with default parameters and predict the class labels for the testing set\n",
    "- Use testing set to train a linear SVM classifier with default parameters and predict the class labels for the training set\n",
    "\n",
    "Q9.1: What is the prediction accuracy using the model trained on the training set:   ___\n",
    "\n",
    "Q9.2: What is the prediction accuracy using the model trained on the testing set:   ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S10: k-NN Error Analysis\n",
    "- In training and testing datasets select the images in categories: 1, 3, 5, 7 or 9\n",
    "- Train k-NN classifiers using 4 to 40 nearest neighbors with a step size of 4\n",
    "- Calculate and plot overall testing accuracy for each experiment\n",
    "\n",
    "Q10.1: For k=4 what is the label that was predicted with lowest accuracy:   ___\n",
    "\n",
    "Q10.2: For k=20 what is the label that was predicted with lowest accuracy:   ___\n",
    "\n",
    "Q10.3: What is the label pair that was confused most often (i.e. class A is labeled as B, and vice versa):   ___\n",
    "\n",
    "Q10.4: Visualize 5 mislabeled samples with their actual and predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S11: Feature extraction\n",
    "\n",
    "- We describe each image by using a reduced set of features (compared to n=784 initial features for each pixel value) as follows:\n",
    "  \n",
    "  1. Binarize the image (background=0, foreground=1)\n",
    "\n",
    "  2. For each image row i, find n_i, the sum of 1's in the row (28 features) \n",
    "  \n",
    "  3. For each image column j, find n_j, the sum of 1's in the column (28 features)\n",
    "  \n",
    "  4. Concatenate these features into a feature vector of 56 features\n",
    "  \n",
    "Repeat classification experiments in S9 using this reduced feature set.\n",
    "\n",
    "Q11.1: What is the prediction accuracy using the model trained using the train data:   ___\n",
    "\n",
    "Q11.2: What is the prediction accuracy using the model trained using the test data:   ___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus:\n",
    "\n",
    "- This time we describe each 28 x 28 image by using a different feature set (n = 28 x 4 features). This feature set encodes \"index of the first non-zero pixel in image columns or rows\" from each direction (from left, right, top, bottom)\n",
    "\n",
    "Example for a 6 x 6 image:\n",
    "\n",
    "Img:\n",
    " 0 0 0 0 0 0\n",
    " 0 0 0 1 0 0\n",
    " 0 0 0 1 0 0\n",
    " 0 0 0 1 0 0\n",
    " 0 0 0 1 0 0\n",
    " 0 0 0 0 0 0\n",
    " \n",
    "Extracted features:\n",
    " 0 3 3 3 3 0  0 2 2 2 2 0  0 0 0 1 0 0  0 0 0 1 0 0   (left, right, top, bottom)\n",
    "  \n",
    "Repeat classification experiments in S9 using this reduced feature set.\n",
    "\n",
    "Q11.1: What is the prediction accuracy using the model trained using the train data:   ___\n",
    "\n",
    "Q11.2: What is the prediction accuracy using the model trained using the test data:   ___\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-650",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1c055c8eaa77772b09e61bca5964f31c66f225d7cac3137222f85c0787dc93f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
